`dotnet --info` -> Get information about ASP.Net installed versions in our computer

`dotnet -h` -> Displays all ASP.Net possible command + explanations

`dotnet new list` -> Displays a list of all project types that can be created in ASP.Net. In this project I'm using the webapi in order to create a RestAPI controllers with endpoints that will be responsible for getting requests from the client, get the data from a database and give it to the client

CREATING an ASP.Net Core WebAPI:
First we need to create a solution file which is quite like a container that will contain all the libraries and projects in our solution

`dotnet new sln` -> Creates a new solution. The name of the solution is derived from the folder from which the creation command was issued

`dotnet new webapi -o <ProjectName> -controllers` -> Creates a webapi project. The -o will create a folder named by the text in the [ProjectName] in which the new project will be hosted. The -controllers is a switch that tells the ASP.Net to create a framework that is based on controllers endpoints

`dotnet new classlib -o <libraryName>` -> Creates a new folder named by the text in the <ProjectName>. We will use the [Core] folder/library as a folder that will hold all the core entities of the solution. We will also create an [Infrastructure] library that will contain all the controllers in the solution. The idea is that when the client sends a request it will be redirected to the [Infrastructure] level. This level will translate the request to HTTP requests that will be sent to the [Core] level. The Core level will be responsible for the interaction with the database

`dotnet sln add <Project / Library name>` -> Adding the projects inside the created solution.

`dotnet sln list` -> Displays all the libraries and projects in the solution

DEFINING THE DEPENDENCIES BETWEEN PROJECTS IN THE SOLUTION
Defining a dependency for a project to be dependent on another project means that the dependent project will have access to the functionality that the other project has. For example - The Infrastructure project relies on the Core project so the Infrastructure code will be able to use the functionality defined in the code inside the Core library

1) Need to go the the folder that is dependent - For example, The API is dependent on the Infrastructure so:
2) `cd <Dependent project>` -> In our project when defining the dependency from API on the Infrastructure - `cd API`
3) `dotnet add reference <project/library location>` (In our project - `dotnet add reference ../Infrastructure`)

BUILDING THE APP - SERVER SIDE
// CREATING THE ENTITIES

This is done in the Core folder. Creating the Entities folder in the Core folder. In the Entities folder - creating the Products class which contains all the required properties for a product.

CREATING THE ENTITY FRAMEWORK CLASSES (Infrastructure folder)
In this phase few additional packages are required from the NUGET package manager:
Important! Always make sure that the version of the EntityFramework matches the major version of the .Net runtime youare using!!!
- `Microsoft.EntityFrameworkCore.SqlServer` -> Install it in the Infrastructure project
- `Microsoft.EntityFrameworkCore.Design` -> Install it in the API project
  
CREATING A DATABASE SERVER WITH SQL SERVER
We run the SQL SERVER through Docker. The docker-compose.yml file defines the container properties. Also in the docker settings we define [2] CPUs, [8GB] memory, [256GB] storage on hard disk, and [1GB] memory for swap files. SQL Server requires a complex password containing capital and non capital letters, numbers and special characters. Not all special characters are excepted ([@] is Ok) and **minimum of 6 (or 8) letters**.
Docker comes with its own networking so we need to specify the external port that is used as the access point to docker, and the second port is used internaly between containers

Running Docker Compose - use the following command (must be in the folder level that contains the docker-compose.yml file):
docker compose up -d -> runs docker
docker compose down -> stop running docker

CREATING MIGRATIONS
To execute migrations we must install the dotnet-ef Nuget Package. Going to the Nuget.org site and finding the dotnet-ef package and installing it globaly (in case it is not installed yet). The version must match the main version that is installed and used in the application (see the targetversion attribute in the csproj file):
`dotnet tool install --global dotnet-ef --version 10.0.0`

Adding a new migration:
`dotnet ef migrations add <migrationName> -s <starterProject> -p <DbContextLocation>`
In our case:
dotnet ef migrations add InitialCreate -s API -p Infrastructure

To remove a migration use the [remove] keyword with the exact parameters:
dotnet ef migrations remove InitialCreate -s API -p Infrastructure

After the migrations we can create / update the database. If the database is not yet created it will be created following this command. It will use the last migration to create / update the database:
dotnet ef database update -s API -p Infrastructure (from the skinet folder)

**[POSTMAN]**
Working with variables in postman.
Clicking on the collection name displays the collection tabs. On the Variables tab it is possible to define a name for the variable and its value and then use it in all the collection's requests
It is also possible to create scripts that will run on every request (can be done also in the request level) such as saving tokens as variables and then using them in other requests.
In the Console view we can see the actual request with all the values of the variables

LOADING TO GITHUB

1) Create a new repository
2) Create a gitignore file using the dotnet command to exclude all the unnesaccary dotnet files using the command: `dotnet new gitignore`
3) To add files to the gitignore, right-click on the file and select the `add to .gitignore` option
4) After creating a new repository on github synchronize between the local files and github by running the following command on the root folder (skinet in this case): `git remote add origin <gitUrl>/<RepoName>.git`. In our case it will be git remote add `origin https://github.com/eranseg74/Skinet.git`
5) Add changes
6) Commit
7) Push

DEBUGGING IN VSCODE
// In the first time we want to run the debugger in VisualStudio Code, we first need to configure the debugger in the `launch.json` file. When we click on the Debug icon we get a link to the `launch.json` file. In the options choose - [C#]. In the launch.json file, clicking on the `Add Configuration` will allow us to choose from various options. Choose 2 options:
1) `.Net: Attach to a .net process`
2) `.Net: Launch C# project` - This allows to run the debugger and launch the application at the same time

In the configuration remove the <relative-path-to-project-folder>. The project path should point to the [projname.csproj] file
In the [name] field in the `.Net: Launch C# project` we can change the name so we will be able to find and select it from the running processes (Here we changed it to API)
When clicking again on the debugger icon we will see the two configurations we selected. Normally we run the application and then select the `.NetCore Attach` option in order to attach the debugger to the running application

SQL-SERVER IN DOCKER
In case we are using SQL-SERVER on Docker we have to set up a volume name. Since all the data will be stored in the dedicated DB in the container, once the container is stopped, all the data is lost. Setting a name to the volume will persist the data even if the container is stopped. The naming must be as follows:
`volumes:`
`- sql-data:/var/opt/mssql` - That is where SQL is expecting to find the data

INSTALLING REDIS
- Configuring the redis in the docker compose file, stopping it and running it again in order to create the DB.
- Install the redis Nuget Package - `StackExchange.Redis @Stack Exchange, Inc.,Marc Gravell,Nick Craver` - We installed it in the Infrastructure project
- Adding the redis as a service in the Program.ts file as a singelton service because we want it to run as long as the application runs

ADDING IDENTITY FRAMEWORK
1) From Nuget install the [Microsoft.Extensions.Identity.Stores] package. This package contains the IdentityUser class from which the AppUser class will be derived. Since the AppUser class will derivefrom the IdentityUser class which is in this package, this Nuget isinstalledin the Core project
2) From Nuget install the [Microsoft.AspNetCore.Identity.EntityFrameworkCore] package in the Infrastructure project
3) Create an AppUser class that will be connected to the User table in the Identity Framework. The class will implement the IdentityUser class from the Identity Framework
4) In the StoreContext change the implements from DbContext to `IdentityDbContext<AppUser>`
5) In the Program.cs add the following services:
   1) `builder.Services.AddAuthorization();`
   2) `builder.Services.AddIdentityApiEndpoints<AppUser>().AddEntityFrameworkStores<StoreContext>();`
6) Also in the Program.cs file add the following after the MapControllers: `app.MapIdentityApi<AppUser>();`
7) Create a new Migration - Go one level up (In this project's case we need to go up to the skinet folder) and run the following command -> dotnet ef migrations add IdentityAdded -s API -p Infrastructure (the general command is:
   dotnet ef migrations add <migration name> -s <starter project> -p <where the StoreContext is>

COOKIES
One of the advantages of cookies on JWT Barear is the HttpOnly flag which blocks the access to cookies using JavaScript. That means that even if we could decode the data in the cookie it does not matter because we cannot access it in the Angular application. It remains in the browser and used in every API call

STEPS FOR ADDING ANOTHER TABLE / ENTITY
1) Create an Entity class in the Entities folder
2) Create a Configuration file for the entity (Here, all the configuration files are in the Infrastructure/Config folder)
3) Create a new DbSet in the StoreContext file
4) If required, create a SeedData file to seed data into the table on initialization
5) Run a migration to add the new data:
   1) Go up to the root level of the project (Here it is the skinet folder)
   2) Run the migration command - `dotnet ef migrations add <migration name> -p <The target project for the command - Where the Migrations folder is> -s <The start project. Here it is the API project>`

STRIPE
1) Assuming account existance in Stripe - Log in to Stripe and create a new account. Use the Sandbox in order to be in test mode.
2) Save the Published Key and the Secret Key in the appsettings file
3) Download required Nuget package: [Stripe.net] in the Infrastructure project
4) Create an Interface for payment intent (IPaymentService) and an implementation service (PaymentService).
5) In the Program.cs class, add the service and interface

Checking Stripe in local environment:
1) Install the Stripe CLI (best using homebrew) with the following command: `brew install stripe/stripe-cli/stripe`
2) Login into the stripe CLI with the following command: `stripe login`. This will prompt a message that will ask you to press enter in order to open the browser. Clicking Enter will open a new tab in the browser and send to the email a 6-digit code. Fill the code you got in the browser. You will get a message in the browser that the login succeeded and also in the command line you will get a message with an account id (the key) and a message that says that this key is valid for 90 days. After 90 days a new authentication is required.
3) After the login, in the command line you get the WhSecret key. Copy it to the appsettings file as the value of the WhSecret key
4) Run the tests against Stripe

SignalR
On the backend side:
1) Create a new folder called SignalR and inside it - creating a class (we called NotificationHub). This class must derive from the Hub class which is in the SignalR namespace. Don't need to install anything because dotnet comes with SignalR
2) Note that SignalR keeps track of the client connection id and that is what the browser usees to maintain a connection with SignalR. This means that if we want to keep track on which user is connected we need to store it in a dictionary that will contain for each email its connection id. In case of multiple servers and clients it is best to keep it in a DB such as Redis for scalability reasons
3) In the Program.cs class 
   1) We need to add the SignalR service - `builder.Services.AddSignalR();`
   2) Make sure to specify the authentication and authorization middleware: `app.UseAuthentication();` and `app.UseAuthorization();`
   3) Provide the mapping so dotnet will know where to forward any requests that come in to our SignalR hub using the following command: `app.MapHub<NotificationHub>("/hub/notifications");` This will map all the incoming requests with the specified path to the specified Microsoft.AspNetCore.SignalR.Hub type.
   4) Inject the NotificationHub (or any class that implements the SignalR). This will give access to the SignalR hub so we can send notifications outside of the hub using this approach.
   5) In the method that will use it we first need to extract the connection id from the DB that maintain the connection between the emails and the connection ids by passing the email of the user.
   6) Then, we can send a message through the SignalR getting the connection using the connectionId and then using the `SendAsync` method to send a message with a message name (string) and the object with all the required data that the client can use.

Preparing the backend for deployment
1) In the Program.cs file:
   1) Define a middleware to serve the static assets from the API using this command: `app.UseDefaultFiles();` which will by default look for the files in the <wwwroot> subfolder. In order to serve the static files we need the following middleware: `app.UseStaticFiles();`.
2) Since the angular files are hosted in the dotnet webserver there are the dotnet API endpoints and there are also Angular routes that are responsible for loading components. When all is in the dotnet webserver, whenever an Angular call is made, dotnet will see it as an API call but since it does not have this call it will return a NotFound result. The following command is needed: `app.MapFallbackToController("Index", "Fallback");`. It will make sure that if dotnet will not succeed in processing the API call it will pass it to Angular to let it handle the call. You will need to implement the FallbackController class which will handle these calls. The Index parameter is the action that will be implemented in the FallbackController class (must be the same name).
3) The <FallbackController>:
   1) Make sure to call it that way.It should match the second parameter in the middleware and end with the <Conroller> text so we won't need to specify it in the middleware. The FallbackController needs to inherit from the Controller class since this class returns a view which is what we need.
4) If we have a seed data, in the StoreContextSeed file we need to define the path as defined in the StoreContextSeed.cs class. Also in the relevant project (in this case it is the Infrastructure project) by defining the following:
   `<None Include="Data\SeedData\**" CopyToOutputDirectory="PreseveNewest" />`
5) Then Go to the root folder (skinet in this case) and reset the DB: `dotnet ef database drop -p Infrastructure -s API`
6) Then go back to the API folder and run the `dotnet build` command. This will create the <bin> and <obj> folders. Inside the <bin>, in the <Debug/net10.0/Data/SeedData> the json files with the seed data will appear
7) Redis - On local environment we use docker to run the Redis DB. When deploying it will not work so we need a cloude solution that hosts Redis DB. We can use the Upstash serverless data platform
8) In the appsettings.development file - update the value of the Redis key to the proprties from the Upstash site